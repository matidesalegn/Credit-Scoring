{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "# Append the src directory to sys.path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_loader import DataLoader\n",
    "from src.eda import EDA\n",
    "from src.feature_engineering import FeatureEngineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 00:19:36,976 - src.logger - INFO - Data loaded successfully from ../data/raw/data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = '../data/raw/data.csv'\n",
    "loader = DataLoader(file_path)\n",
    "data = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Feature Engineering\n",
    "fe = FeatureEngineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 00:19:37,000 - src.logger - INFO - Creating aggregate features...\n",
      "2024-06-07 00:19:37,000 - src.logger - INFO - Creating aggregate features...\n"
     ]
    }
   ],
   "source": [
    "# Create Aggregate Features\n",
    "data = fe.create_aggregate_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 00:19:37,057 - src.logger - INFO - Extracting temporal features...\n",
      "2024-06-07 00:19:37,057 - src.logger - INFO - Extracting temporal features...\n"
     ]
    }
   ],
   "source": [
    "# Extract Temporal Features\n",
    "data = fe.extract_temporal_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Categorical Variables...\n"
     ]
    }
   ],
   "source": [
    "# Encode Categorical Variables\n",
    "print(\"Encoding Categorical Variables...\")\n",
    "cat_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# One-Hot Encoding for categorical variables with fewer categories\n",
    "for col in cat_cols:\n",
    "    if data[col].nunique() < 10:\n",
    "        ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "        ohe_df = pd.DataFrame(ohe.fit_transform(data[[col]]), columns=ohe.get_feature_names_out([col]))\n",
    "        data = pd.concat([data, ohe_df], axis=1).drop(columns=[col])\n",
    "    else:\n",
    "        # Label Encoding for categorical variables with more categories\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 00:19:38,433 - src.logger - INFO - Handling missing values...\n",
      "2024-06-07 00:19:38,433 - src.logger - INFO - Handling missing values...\n",
      "d:\\credit scoring system\\notebooks\\..\\src\\feature_engineering.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.df[col].fillna(self.df[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle Missing Values\n",
    "data = fe.handle_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 00:19:38,505 - src.logger - INFO - Normalizing features...\n",
      "2024-06-07 00:19:38,505 - src.logger - INFO - Normalizing features...\n"
     ]
    }
   ],
   "source": [
    "# Normalize Numerical Features\n",
    "data = fe.normalize_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing Numerical Features...\n"
     ]
    }
   ],
   "source": [
    "# Standardize Numerical Features\n",
    "print(\"Standardizing Numerical Features...\")\n",
    "num_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data\n",
    "data.to_csv('../data/processed/processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 10:09:20,916 - src.logger - INFO - Data loaded successfully from ../data/raw/data.csv\n",
      "2024-06-08 10:09:20,916 - src.logger - INFO - Data loaded successfully from ../data/raw/data.csv\n",
      "2024-06-08 10:09:20,918 - src.logger - INFO - Creating aggregate features...\n",
      "2024-06-08 10:09:20,918 - src.logger - INFO - Creating aggregate features...\n",
      "2024-06-08 10:09:20,918 - src.logger - INFO - Creating aggregate features...\n",
      "2024-06-08 10:09:20,974 - src.logger - INFO - Extracting temporal features...\n",
      "2024-06-08 10:09:20,974 - src.logger - INFO - Extracting temporal features...\n",
      "2024-06-08 10:09:20,974 - src.logger - INFO - Extracting temporal features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Categorical Variables...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 10:09:21,985 - src.logger - INFO - Handling missing values...\n",
      "2024-06-08 10:09:21,985 - src.logger - INFO - Handling missing values...\n",
      "2024-06-08 10:09:21,985 - src.logger - INFO - Handling missing values...\n",
      "d:\\credit scoring system\\notebooks\\..\\src\\feature_engineering.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.df[col].fillna(self.df[col].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying WoE Transformation...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\credit scoring system\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m woe \u001b[38;5;241m=\u001b[39m WOE()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Assuming 'target' is the target variable column\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m data_woe \u001b[38;5;241m=\u001b[39m woe\u001b[38;5;241m.\u001b[39mfit_transform(data, \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Standardize Numerical Features\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStandardizing Numerical Features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\credit scoring system\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\credit scoring system\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "# notebooks/FeatureEngineering.ipynb\n",
    "\n",
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from xverse.transformer import WOE\n",
    "\n",
    "# Append the src directory to sys.path\n",
    "# Append the src directory to sys.path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_loader import DataLoader\n",
    "from src.eda import EDA\n",
    "from src.feature_engineering import FeatureEngineering\n",
    "\n",
    "# Load the data\n",
    "file_path = '../data/raw/data.csv'\n",
    "loader = DataLoader(file_path)\n",
    "data = loader.load_data()\n",
    "\n",
    "# Perform Feature Engineering\n",
    "fe = FeatureEngineering(data)\n",
    "\n",
    "# Create Aggregate Features\n",
    "data = fe.create_aggregate_features()\n",
    "\n",
    "# Extract Temporal Features\n",
    "data = fe.extract_temporal_features()\n",
    "\n",
    "# Encode Categorical Variables\n",
    "print(\"Encoding Categorical Variables...\")\n",
    "cat_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# One-Hot Encoding for categorical variables with fewer categories\n",
    "for col in cat_cols:\n",
    "    if data[col].nunique() < 10:\n",
    "        ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "        ohe_df = pd.DataFrame(ohe.fit_transform(data[[col]]), columns=ohe.get_feature_names_out([col]))\n",
    "        data = pd.concat([data, ohe_df], axis=1).drop(columns=[col])\n",
    "    else:\n",
    "        # Label Encoding for categorical variables with more categories\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Handle Missing Values\n",
    "data = fe.handle_missing_values()\n",
    "\n",
    "# Apply WoE Transformation\n",
    "print(\"Applying WoE Transformation...\")\n",
    "woe = WOE()\n",
    "# Assuming 'target' is the target variable column\n",
    "data_woe = woe.fit_transform(data, data['FraudResult'])\n",
    "\n",
    "# Standardize Numerical Features\n",
    "print(\"Standardizing Numerical Features...\")\n",
    "num_cols = data_woe.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "data_woe[num_cols] = scaler.fit_transform(data_woe[num_cols])\n",
    "\n",
    "# Save the processed data\n",
    "processed_file_path = '../data/processed/processed_data.csv'\n",
    "os.makedirs(os.path.dirname(processed_file_path), exist_ok=True)\n",
    "data_woe.to_csv(processed_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved to {processed_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
